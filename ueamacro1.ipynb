{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NikosAng/UEA-macro-lectures/blob/main/ueamacro1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39d37dd0-5372-493b-bdba-df85ae90da6f",
      "metadata": {
        "trusted": true,
        "id": "39d37dd0-5372-493b-bdba-df85ae90da6f"
      },
      "outputs": [],
      "source": [
        "!pip -q install pandas_datareader ruptures pmdarima\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pandas_datareader import data as web\n",
        "from statsmodels.tsa.stattools import adfuller, kpss, zivot_andrews, coint\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "plt.rcParams[\"figure.dpi\"] = 110\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Pull & Inspect Data\n",
        "\n",
        "1. **Fetch real GDP**  \n",
        "   We use the FRED series `GDPC1` (Real Gross Domestic Product) from 1950-01-01 onward.\n",
        "\n",
        "2. **Align to quarter-ends**  \n",
        "   To ensure a clean quarterly frequency, we resample with `.resample('Q').last()`, which takes the last observation within each calendar quarter.\n",
        "\n",
        "3. **Quick sanity check**  \n",
        "   - Display the first few rows to confirm the series is loaded correctly.  \n",
        "   - Print the count of non-missing values to verify that we have a complete quarterly history.\n"
      ],
      "metadata": {
        "id": "RCIiOgRBYmy4"
      },
      "id": "RCIiOgRBYmy4"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Pull & Inspect Data\n",
        "# Fetch quarterly real GDP from FRED\n",
        "gdp = web.DataReader(\"GDPC1\", \"fred\", \"1950-01-01\")\n",
        "# Resample to exact quarter-ends\n",
        "gdp = gdp.resample(\"Q\").last()\n",
        "\n",
        "print(\"GDP head:\")\n",
        "display(gdp.head())\n",
        "print(\"Non-missing count:\", gdp.count().GDPC1)\n"
      ],
      "metadata": {
        "id": "IxF-3wj_XqVm"
      },
      "id": "IxF-3wj_XqVm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Simulate TS vs DS (Intuition)\n",
        "\n",
        "Before diving into real data, let’s build simple toy series to see the difference between:\n",
        "\n",
        "- **Trend-Stationary (TS)**: fluctuations that revert to a fixed, deterministic trend.\n",
        "- **Difference-Stationary (DS)**: a pure random walk with drift, where shocks permanently shift the level.\n",
        "\n",
        "**What the code does:**\n",
        "1. **Set a random seed** for reproducibility.\n",
        "2. **TS series**  \n",
        "   - Generate AR(1) noise with coefficient φ = 0.8.  \n",
        "   - Add a deterministic linear trend (0.05 per period) to the noise.  \n",
        "   - Results in a series that wanders but always pulls back toward the trend.\n",
        "3. **DS series**  \n",
        "   - Simulate a random walk with constant drift (0.02 per period).  \n",
        "   - Each shock accumulates permanently.\n",
        "4. **Plot both** on the same axes to visualise:  \n",
        "   - The TS path hovers around its trend line.  \n",
        "   - The DS path continuously drifts as shocks accumulate."
      ],
      "metadata": {
        "id": "Elt3TQWHYus2"
      },
      "id": "Elt3TQWHYus2"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 3. Simulate TS vs DS (intuition)\n",
        "np.random.seed(1)\n",
        "T=200\n",
        "# TS: linear trend + AR(1) noise\n",
        "phi=0.8; u=np.zeros(T)\n",
        "for t in range(1,T): u[t]=phi*u[t-1]+np.random.randn()*0.5\n",
        "ts = 0.05*np.arange(T)+u\n",
        "# DS: random walk with drift\n",
        "rw = np.cumsum(0.02+np.random.randn(T)*0.5)\n",
        "\n",
        "plt.plot(ts, label=\"TS (trend-stationary)\")\n",
        "plt.plot(rw, label=\"DS (unit-root)\")\n",
        "plt.legend(); plt.title(\"Simulated TS vs DS\"); plt.show()\n"
      ],
      "metadata": {
        "id": "s5GXNOZoXvKW"
      },
      "id": "s5GXNOZoXvKW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. ADF & KPSS Helper + Unit-Root Tests\n",
        "\n",
        "In this cell we:\n",
        "\n",
        "1. **Define a helper function** `unitroot_tests(y, name)` that:\n",
        "   - Drops any missing values.\n",
        "   - Prints the sample size (`n`).\n",
        "   - Runs the **Augmented Dickey–Fuller (ADF)** test for a unit root (`H₀: I(1)`).\n",
        "   - Runs the **KPSS** test for stationarity (`H₀: I(0)`).\n",
        "   - Reports both p-values side by side for quick comparison.\n",
        "\n",
        "2. **Prepare our series**:\n",
        "   - `log_gdp`: the natural log of real GDP (levels) with NAs removed.\n",
        "   - `dlog_gdp`: the first difference of `log_gdp` (i.e. growth rates), also NA-cleaned.\n",
        "\n",
        "3. **Run the tests** on each series:\n",
        "   - If **ADF p-value < 0.05**, we reject the unit‐root null in favor of stationarity.\n",
        "   - If **KPSS p-value < 0.05**, we reject the stationarity null in favor of a unit root.\n",
        "   - Together, these give a more robust picture of whether the series is truly I(0) or I(1).\n"
      ],
      "metadata": {
        "id": "_byW1cBGY0Av"
      },
      "id": "_byW1cBGY0Av"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 4. ADF & KPSS Helper + Tests\n",
        "def unitroot_tests(y, name):\n",
        "    y = y.dropna()\n",
        "    print(f\"→ {name}:  n={len(y)} obs\")\n",
        "    adf_p = adfuller(y, autolag=\"AIC\")[1]\n",
        "    kpss_p= kpss(y, nlags=\"auto\", regression=\"c\")[1]\n",
        "    print(f\"    ADF  p-value = {adf_p:.3f}\")\n",
        "    print(f\"    KPSS p-value = {kpss_p:.3f}\\n\")\n",
        "\n",
        "# Prepare series\n",
        "log_gdp  = np.log(gdp[\"GDPC1\"]).dropna()\n",
        "dlog_gdp = log_gdp.diff().dropna()\n",
        "\n",
        "# Run tests\n",
        "unitroot_tests(log_gdp,  \"log GDP level\")\n",
        "unitroot_tests(dlog_gdp, \"Δ log GDP growth\")\n"
      ],
      "metadata": {
        "id": "4lC7PIFEXx3u"
      },
      "id": "4lC7PIFEXx3u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "J4tY4-jSYzSf"
      },
      "id": "J4tY4-jSYzSf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Structural Break Test (Zivot–Andrews)\n",
        "\n",
        "We now test whether the log-level GDP series has an endogenous break in its intercept (e.g. a sudden shift in mean) that could invalidate standard unit-root tests.\n",
        "\n",
        "1. **Import** the `zivot_andrews` function.  \n",
        "2. **Copy** the cleaned `log_gdp` series into `y`.  \n",
        "3. **Run** `zivot_andrews(y, maxlag=8, regression='c')`, which:\n",
        "   - Searches over all possible break dates (up to 8 lags from each end) to find the date that makes the null of a unit root hardest to reject.\n",
        "   - Returns **five** values:\n",
        "     - `za_stat`: the Zivot–Andrews test statistic.\n",
        "     - `za_p`: its approximate p-value.\n",
        "     - `za_crit`: a dictionary of critical values.\n",
        "     - `za_lag`: the lag length actually used in the final regression.\n",
        "     - `za_bp`: the integer index (position in the series) of the estimated break point.\n",
        "\n",
        "4. **Print** all five to understand:\n",
        "   - Whether there is strong evidence of a break (`p < 0.05`),  \n",
        "   - The precise break quarter,  \n",
        "   - And the critical thresholds against which the test is compared.\n"
      ],
      "metadata": {
        "id": "87XrLWVFY7vu"
      },
      "id": "87XrLWVFY7vu"
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Structural Break Test (Zivot–Andrews)\n",
        "from statsmodels.tsa.stattools import zivot_andrews\n",
        "\n",
        "y = log_gdp.copy()\n",
        "\n",
        "# unpack all 5 returns: stat, p‐value, crit‐dict, used‐lag, break‐location\n",
        "za_stat, za_p, za_crit, za_lag, za_bp = zivot_andrews(y, maxlag=8, regression=\"c\")\n",
        "\n",
        "print(f\"Zivot–Andrews statistic = {za_stat:.3f}\")\n",
        "print(f\"p-value                  = {za_p:.3f}\")\n",
        "print(f\"critical values          = {za_crit}\")\n",
        "print(f\"chosen lag               = {za_lag}\")\n",
        "print(f\"break at index           = {za_bp}  → quarter = {y.index[za_bp].date()}\")\n"
      ],
      "metadata": {
        "id": "NT-PZxQoX1Ju"
      },
      "id": "NT-PZxQoX1Ju",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. AR(1) Fit → Half-Life & Impulse Response\n",
        "\n",
        "In this cell we quantify how quickly GDP growth shocks decay using a simple AR(1) model:\n",
        "\n",
        "1. **Fit an AR(1)**  \n",
        "   - We model the growth series `dlog_gdp` as  \n",
        "     \\[\n",
        "       y_t = \\phi \\, y_{t-1} + \\varepsilon_t.\n",
        "     \\]\n",
        "   - Use `statsmodels`’ `ARIMA(order=(1,0,0))` to estimate the coefficient \\(\\phi\\).\n",
        "\n",
        "2. **Compute the half-life**  \n",
        "   - The half-life \\(HL\\) is the number of periods it takes for a one-unit shock to decay to 50% of its initial impact:\n",
        "     \\[\n",
        "       HL = \\frac{\\ln(0.5)}{\\ln|\\phi|}.\n",
        "     \\]\n",
        "   - Print the estimated \\(\\phi\\) and the corresponding half-life in quarters.\n",
        "\n",
        "3. **Plot the Impulse Response Function (IRF)**  \n",
        "   - For an AR(1), the IRF at horizon \\(h\\) is simply \\(\\psi_h = \\phi^h\\).  \n",
        "   - We stem-plot \\(\\psi_h\\) for \\(h = 0,1,\\dots,19\\) to visualize how the effect of a shock decays over time.\n"
      ],
      "metadata": {
        "id": "3HGN5xbWZFMw"
      },
      "id": "3HGN5xbWZFMw"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 6. AR(1) Fit → Half-Life & IRF (fixed stem call)\n",
        "y = dlog_gdp.copy()\n",
        "model = ARIMA(y, order=(1,0,0)).fit()\n",
        "phi = model.params[\"ar.L1\"]\n",
        "hl  = np.log(0.5)/np.log(abs(phi))\n",
        "print(f\"Estimated φ = {phi:.3f}\")\n",
        "print(f\"Half-Life ≈ {hl:.1f} quarters\")\n",
        "\n",
        "# IRF\n",
        "H = 20\n",
        "psi = phi**np.arange(H)\n",
        "plt.stem(np.arange(H), psi, basefmt=\" \")\n",
        "plt.title(\"AR(1) Impulse Response\")\n",
        "plt.xlabel(\"horizon\")\n",
        "plt.ylabel(\"ψₕ\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qjuaz1alYMrX"
      },
      "id": "qjuaz1alYMrX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we use the Variance‐Ratio (VR) test to gauge persistence without imposing an ARMA structure:\n",
        "\n",
        "**1. Compute the VR statistic**  \n",
        "For each horizon \\(k = 1, \\dots, 40\\), we calculate  \n",
        "\\[\n",
        "\\mathrm{VR}(k) \\;=\\; \\frac{\\Var(y_t - y_{t-k})}{k \\,\\Var(\\Delta y_t)}.\n",
        "\\]\n",
        "\n",
        "- If \\(y_t\\) is a pure random walk (\\(I(1)\\)), then \\(\\mathrm{VR}(k)\\approx1\\) for all \\(k\\).  \n",
        "- If \\(y_t\\) is stationary (\\(I(0)\\)), then \\(\\mathrm{VR}(k)\\to0\\) as \\(k\\to\\infty\\).  \n",
        "- Intermediate values indicate a mixture of permanent and transitory components.\n",
        "\n",
        "**2. Bootstrap a confidence band**  \n",
        "- Resample the first differences \\(\\Delta y_t\\) with replacement \\(B=200\\) times.  \n",
        "- For each bootstrap sample, recompute the VR profile.  \n",
        "- Take the 2.5 % and 97.5 % quantiles at each \\(k\\) to form a Monte Carlo confidence interval.\n",
        "\n",
        "**3. Plot and interpret**  \n",
        "- **Solid line**: the empirical VR curve.  \n",
        "- **Shaded band**: the 95 % bootstrap confidence interval.  \n",
        "- **Dashed horizontal line** at 1: the random-walk benchmark.  \n",
        "\n",
        "If the VR curve lies significantly below 1 (outside the band) for large \\(k\\), that indicates strong mean reversion (stationarity). If it hovers near 1, the series behaves more like a unit root.\n"
      ],
      "metadata": {
        "id": "m28Cr4UcZMkp"
      },
      "id": "m28Cr4UcZMkp"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 7. Variance-Ratio Profile (with bootstrap CI)\n",
        "def vr_profile(y, max_h=40, B=200):\n",
        "    y = y.dropna().to_numpy()\n",
        "    d = np.diff(y); v1 = np.var(d, ddof=0)\n",
        "    vr = [np.var(y[h:]-y[:-h], ddof=0)/(h*v1) for h in range(1,max_h+1)]\n",
        "    boot = []\n",
        "    for _ in range(B):\n",
        "        db = np.random.choice(d, size=len(d), replace=True)\n",
        "        yb = np.insert(np.cumsum(db), 0, y[0])\n",
        "        v1b = np.var(np.diff(yb), ddof=0)\n",
        "        boot.append([np.var(yb[h:]-yb[:-h], ddof=0)/(h*v1b) for h in range(1,max_h+1)])\n",
        "    ci = np.percentile(boot, [2.5,97.5], axis=0)\n",
        "    return np.array(vr), ci\n",
        "\n",
        "vr, ci = vr_profile(log_gdp)\n",
        "h = np.arange(1,len(vr)+1)\n",
        "plt.plot(h, vr, label=\"VR(k)\")\n",
        "plt.fill_between(h, ci[0], ci[1], color=\"gray\", alpha=0.3)\n",
        "plt.axhline(1, ls=\"--\", color=\"k\")\n",
        "plt.title(\"Variance-Ratio Profile (log GDP)\"); plt.xlabel(\"k\"); plt.ylabel(\"VR\"); plt.show()\n"
      ],
      "metadata": {
        "id": "Z7jgsJTPYSBI"
      },
      "id": "Z7jgsJTPYSBI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Toy NK IRFs & Persistence Variation\n",
        "\n",
        "To see how persistence alters policy‐relevant dynamics, we plot “toy” impulse‐response functions (IRFs) of a typical New-Keynesian variable (like the output gap or inflation) under three different persistence parameters \\(\\rho\\):\n",
        "\n",
        "- **\\(\\rho=0.3\\)**: low persistence — shocks die out quickly.  \n",
        "- **\\(\\rho=0.6\\)**: moderate persistence — shocks linger for several periods.  \n",
        "- **\\(\\rho=0.9\\)**: high persistence — shocks have long-lasting effects.\n",
        "\n",
        "The IRF at horizon \\(h\\) is simply \\(\\rho^h\\). By overlaying these curves, you can immediately see that:\n",
        "\n",
        "- With **low \\(\\rho\\)**, the response nearly vanishes within a few quarters.  \n",
        "- With **high \\(\\rho\\)**, the response remains substantially above zero even at long horizons.\n",
        "\n",
        "This illustrates why accurate persistence measurement matters: policy rules (e.g. Taylor rules) must be calibrated to match the true inertia of the economy.  \n"
      ],
      "metadata": {
        "id": "eGXe-5UQZdTL"
      },
      "id": "eGXe-5UQZdTL"
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 9. Toy NK IRFs & Persistence Variation\n",
        "import matplotlib.pyplot as plt\n",
        "H=20\n",
        "# Base IRFs\n",
        "for rho in [0.3, 0.6, 0.9]:\n",
        "    irf = rho**np.arange(H)\n",
        "    plt.plot(irf, label=f\"ρ={rho}\")\n",
        "plt.axhline(0, color='k', lw=0.5)\n",
        "plt.title(\"Toy NK IRFs (output gap or inflation)\"); plt.xlabel(\"quarters\")\n",
        "plt.legend(); plt.show()\n"
      ],
      "metadata": {
        "id": "kybrqcF3YVGu"
      },
      "id": "kybrqcF3YVGu",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}